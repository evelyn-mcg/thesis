{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d8a5147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6f3f6ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re #regex for cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da3211c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[1;32m      2\u001b[0m nlp \u001b[38;5;241m=\u001b[39m spacy\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men_core_web_sm\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1915cc64",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fasttext'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/z_/pjq4h8255nj3yc53_06_63440000gn/T/ipykernel_53423/1264288433.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mfasttext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fasttext'"
     ]
    }
   ],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68e6b658",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/eviemcgonigle/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/eviemcgonigle/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/eviemcgonigle/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/eviemcgonigle/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "35d0e422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "      <th>created</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>Migrants Occupy $288 a Night NYC Hotel, Refuse...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yuri_2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>BREAKING: Nikki Haley to run for president in ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yuri_2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>It's the land of the freebies for NYC's 'entit...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yuri_2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>[VIDEO] Joe Biden Has Another Outburst and Sta...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SharkolyPamuk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[removed]</td>\n",
       "      <td>Liberals giving this man 180 sentence only</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ZoneZeus123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    selftext                                              title  created  \\\n",
       "0             Migrants Occupy $288 a Night NYC Hotel, Refuse...      NaN   \n",
       "1             BREAKING: Nikki Haley to run for president in ...      NaN   \n",
       "2             It's the land of the freebies for NYC's 'entit...      NaN   \n",
       "3             [VIDEO] Joe Biden Has Another Outburst and Sta...      NaN   \n",
       "4  [removed]         Liberals giving this man 180 sentence only      NaN   \n",
       "\n",
       "          author  \n",
       "0      yuri_2022  \n",
       "1      yuri_2022  \n",
       "2      yuri_2022  \n",
       "3  SharkolyPamuk  \n",
       "4    ZoneZeus123  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "with open('./data/raw/r_republican_23posts.jsonl', 'r') as file:\n",
    "    # Iterate through each line in the JSONL file\n",
    "    for json_str in file:\n",
    "        # Load each line as a JSON object\n",
    "        result = json.loads(json_str)\n",
    "        \n",
    "        # Extract the desired fields if they exist and append them to the list\n",
    "        data.append({\n",
    "            'selftext': result.get('selftext', None),\n",
    "            'title': result.get('title', None),\n",
    "            'created': result.get('created', None),\n",
    "            'author': result.get('author', None)\n",
    "        })\n",
    "\n",
    "# Create a pandas DataFrame from the list\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f420033a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate text data so we have just an author/text per post\n",
    "\n",
    "#remove \"[removed]\" from selftext field\n",
    "df['selftext'] = df['selftext'].replace('[removed]', '', regex=False)\n",
    "\n",
    "#create text column\n",
    "df['text'] = df['selftext'].fillna('') + \" \" + df['title']\n",
    "data = df[['author', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "434e4b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#based off evolving divergence paper\n",
    "#removes long posts that are duplicates in author/text\n",
    "#removes repetitive URLS\n",
    "def filter_spam(df):\n",
    "    df = df[(df['text'].str.len() <= 90) | \n",
    "                    ((df['text'].str.len() > 90) & \n",
    "                     ~df.duplicated(subset=['author', 'text']))]\n",
    "    \n",
    "    #remove bot - like patterns?\n",
    "    \n",
    "    #extract spammy urls\n",
    "    df.loc[:, 'url'] = df['text'].str.extract(r\"(https://\\S+)\")\n",
    "    spam_urls = df['url'].value_counts().nlargest(30).index\n",
    "\n",
    "    df = df[~df['url'].isin(spam_urls)]  # remove posts containing spam urls\n",
    "    \n",
    "    \n",
    "    #remove user/subreddit mentions\n",
    "    df['text'] = df['text'].str.replace(r\"(/r/\\w+)\", \" \", regex=True)\n",
    "    df['text'] = df['text'].str.replace(r\"(/u/\\w+)\", \" \", regex=True)\n",
    "    \n",
    "    #remove urls\n",
    "    df['text'] = df['text'].str.replace(r\"http[s]?://\\S+\", \" \", regex=True)\n",
    "    \n",
    "    #extra spaces\n",
    "    df['text'] = df['text'].str.replace(r\"\\s+\", \" \", regex=True)\\\n",
    "        .str.strip()          #leading/trailing spaces\n",
    "    \n",
    "    return df\n",
    "        \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "972dcd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new df with sentences, authors instead of post_text, authors\n",
    "def to_sentences(row):\n",
    "    author = row['author']\n",
    "    text = row['text']\n",
    "    \n",
    "    all_sent = sent_tokenize(text)\n",
    "    \n",
    "    df_sent = [{'author': author, 'sentence': sentence} for sentence in all_sent]\n",
    "    \n",
    "    return df_sent\n",
    "\n",
    "def text_cleaner(post):\n",
    "    \n",
    "    post = post.lower()  #lower case all text\n",
    "    \n",
    "    post = re.sub(r'[^a-zA-Z0-9\\s]', '', post) #remove special char\n",
    "    \n",
    "    #will add more specific substitutions\n",
    "    #removing numbers\n",
    "    #removing abbrev/acronyms\n",
    "    \n",
    "    return post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "edb4f2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removes stop words, and lemmatizes\n",
    "def lemma_er(post):\n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    post = [word for word in post if word not in stop_words]\n",
    "    \n",
    "    post = [lemmatizer.lemmatize(word) for word in post]\n",
    "    \n",
    "    return post\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5cfab73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z_/pjq4h8255nj3yc53_06_63440000gn/T/ipykernel_53423/1848685688.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'url'] = df['text'].str.extract(r\"(https://\\S+)\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yuri_2022</td>\n",
       "      <td>Migrants Occupy $288 a Night NYC Hotel, Refus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yuri_2022</td>\n",
       "      <td>BREAKING: Nikki Haley to run for president in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yuri_2022</td>\n",
       "      <td>It's the land of the freebies for NYC's 'enti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SharkolyPamuk</td>\n",
       "      <td>[VIDEO] Joe Biden Has Another Outburst and St...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZoneZeus123</td>\n",
       "      <td>Liberals giving this man 180 sentence only</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          author                                           sentence\n",
       "0      yuri_2022   Migrants Occupy $288 a Night NYC Hotel, Refus...\n",
       "1      yuri_2022   BREAKING: Nikki Haley to run for president in...\n",
       "2      yuri_2022   It's the land of the freebies for NYC's 'enti...\n",
       "3  SharkolyPamuk   [VIDEO] Joe Biden Has Another Outburst and St...\n",
       "4    ZoneZeus123         Liberals giving this man 180 sentence only"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#main\n",
    "data = filter_spam(data)\n",
    "\n",
    "#split text into sentences - nec for fasttext\n",
    "\n",
    "sentence_data = df.apply(to_sentences, axis=1)\n",
    "flat_sentences = [item for sublist in sentence_data for item in sublist]\n",
    "sents = pd.DataFrame(flat_sentences)\n",
    "\n",
    "sents.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6a2de642",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean text\n",
    "sents['clean_text'] = sents['sentence'].apply(text_cleaner)\n",
    "\n",
    "sents['tokens'] = sents['clean_text'].apply(word_tokenize)\n",
    "#remove rows \n",
    "\n",
    "\n",
    "#THERE IS AN ISSUE WITH THE WORD_TOKENIZE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d56b9d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents['tokens'] = sents['clean_text'].apply(lambda x: word_tokenize(x) if x.strip() else [])\n",
    "\n",
    "#remove empty token rows\n",
    "sents = sents[sents['tokens'].apply(lambda x: len(x) > 0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "56b9f473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>sentence</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2075</th>\n",
       "      <td>agjrpsl</td>\n",
       "      <td>TINY D wants to break up GOOGLE.</td>\n",
       "      <td>tiny d wants to break up google</td>\n",
       "      <td>[tiny, d, wants, to, break, up, google]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2076</th>\n",
       "      <td>LengthinessTall166</td>\n",
       "      <td>Trump needs a lesson on jail lingo</td>\n",
       "      <td>trump needs a lesson on jail lingo</td>\n",
       "      <td>[trump, needs, a, lesson, on, jail, lingo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2077</th>\n",
       "      <td>Excellent-Gold6560</td>\n",
       "      <td>\"But it's (D)ifferent\" nope hope you you</td>\n",
       "      <td>but its different nope hope you you</td>\n",
       "      <td>[but, its, different, nope, hope, you, you]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2078</th>\n",
       "      <td>futurific</td>\n",
       "      <td>Man arrested for alleged child molestation du...</td>\n",
       "      <td>man arrested for alleged child molestation du...</td>\n",
       "      <td>[man, arrested, for, alleged, child, molestati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079</th>\n",
       "      <td>CarRemarkable2704</td>\n",
       "      <td>And Another one Gone .... And Another one Gon...</td>\n",
       "      <td>and another one gone  and another one gone</td>\n",
       "      <td>[and, another, one, gone, and, another, one, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12025</th>\n",
       "      <td>agjrpsl</td>\n",
       "      <td>Trump Co-Defendant in Georgia Election Interf...</td>\n",
       "      <td>trump codefendant in georgia election interfe...</td>\n",
       "      <td>[trump, codefendant, in, georgia, election, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12026</th>\n",
       "      <td>agjrpsl</td>\n",
       "      <td>Trump’s Promise of Lawlessness</td>\n",
       "      <td>trumps promise of lawlessness</td>\n",
       "      <td>[trumps, promise, of, lawlessness]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12027</th>\n",
       "      <td>RealityUSA2023</td>\n",
       "      <td>BREAKING: The FBI arrests the fugitive member...</td>\n",
       "      <td>breaking the fbi arrests the fugitive member ...</td>\n",
       "      <td>[breaking, the, fbi, arrests, the, fugitive, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12028</th>\n",
       "      <td>wdcmsnbcgay</td>\n",
       "      <td>Homophobe Matt Gaetz Seeks Democratic Allianc...</td>\n",
       "      <td>homophobe matt gaetz seeks democratic allianc...</td>\n",
       "      <td>[homophobe, matt, gaetz, seeks, democratic, al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12029</th>\n",
       "      <td>wenchette</td>\n",
       "      <td>GOP senators say they won't stop Democrats fr...</td>\n",
       "      <td>gop senators say they wont stop democrats fro...</td>\n",
       "      <td>[gop, senators, say, they, wont, stop, democra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9811 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   author                                           sentence  \\\n",
       "2075              agjrpsl                   TINY D wants to break up GOOGLE.   \n",
       "2076   LengthinessTall166                 Trump needs a lesson on jail lingo   \n",
       "2077   Excellent-Gold6560           \"But it's (D)ifferent\" nope hope you you   \n",
       "2078            futurific   Man arrested for alleged child molestation du...   \n",
       "2079    CarRemarkable2704   And Another one Gone .... And Another one Gon...   \n",
       "...                   ...                                                ...   \n",
       "12025             agjrpsl   Trump Co-Defendant in Georgia Election Interf...   \n",
       "12026             agjrpsl                     Trump’s Promise of Lawlessness   \n",
       "12027      RealityUSA2023   BREAKING: The FBI arrests the fugitive member...   \n",
       "12028         wdcmsnbcgay   Homophobe Matt Gaetz Seeks Democratic Allianc...   \n",
       "12029           wenchette   GOP senators say they won't stop Democrats fr...   \n",
       "\n",
       "                                              clean_text  \\\n",
       "2075                     tiny d wants to break up google   \n",
       "2076                  trump needs a lesson on jail lingo   \n",
       "2077                 but its different nope hope you you   \n",
       "2078    man arrested for alleged child molestation du...   \n",
       "2079         and another one gone  and another one gone    \n",
       "...                                                  ...   \n",
       "12025   trump codefendant in georgia election interfe...   \n",
       "12026                      trumps promise of lawlessness   \n",
       "12027   breaking the fbi arrests the fugitive member ...   \n",
       "12028   homophobe matt gaetz seeks democratic allianc...   \n",
       "12029   gop senators say they wont stop democrats fro...   \n",
       "\n",
       "                                                  tokens  \n",
       "2075             [tiny, d, wants, to, break, up, google]  \n",
       "2076          [trump, needs, a, lesson, on, jail, lingo]  \n",
       "2077         [but, its, different, nope, hope, you, you]  \n",
       "2078   [man, arrested, for, alleged, child, molestati...  \n",
       "2079   [and, another, one, gone, and, another, one, g...  \n",
       "...                                                  ...  \n",
       "12025  [trump, codefendant, in, georgia, election, in...  \n",
       "12026                 [trumps, promise, of, lawlessness]  \n",
       "12027  [breaking, the, fbi, arrests, the, fugitive, m...  \n",
       "12028  [homophobe, matt, gaetz, seeks, democratic, al...  \n",
       "12029  [gop, senators, say, they, wont, stop, democra...  \n",
       "\n",
       "[9811 rows x 4 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents.iloc[2040:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0ecc222a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>sentence</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>out_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yuri_2022</td>\n",
       "      <td>Migrants Occupy $288 a Night NYC Hotel, Refus...</td>\n",
       "      <td>migrants occupy 288 a night nyc hotel refuse ...</td>\n",
       "      <td>[migrants, occupy, 288, a, night, nyc, hotel, ...</td>\n",
       "      <td>[migrant, occupy, 288, night, nyc, hotel, refu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yuri_2022</td>\n",
       "      <td>BREAKING: Nikki Haley to run for president in...</td>\n",
       "      <td>breaking nikki haley to run for president in ...</td>\n",
       "      <td>[breaking, nikki, haley, to, run, for, preside...</td>\n",
       "      <td>[breaking, nikki, haley, run, president, 2024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yuri_2022</td>\n",
       "      <td>It's the land of the freebies for NYC's 'enti...</td>\n",
       "      <td>its the land of the freebies for nycs entitle...</td>\n",
       "      <td>[its, the, land, of, the, freebies, for, nycs,...</td>\n",
       "      <td>[land, freebie, nycs, entitled, migrant]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SharkolyPamuk</td>\n",
       "      <td>[VIDEO] Joe Biden Has Another Outburst and St...</td>\n",
       "      <td>video joe biden has another outburst and star...</td>\n",
       "      <td>[video, joe, biden, has, another, outburst, an...</td>\n",
       "      <td>[video, joe, biden, another, outburst, start, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZoneZeus123</td>\n",
       "      <td>Liberals giving this man 180 sentence only</td>\n",
       "      <td>liberals giving this man 180 sentence only</td>\n",
       "      <td>[liberals, giving, this, man, 180, sentence, o...</td>\n",
       "      <td>[liberal, giving, man, 180, sentence]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          author                                           sentence  \\\n",
       "0      yuri_2022   Migrants Occupy $288 a Night NYC Hotel, Refus...   \n",
       "1      yuri_2022   BREAKING: Nikki Haley to run for president in...   \n",
       "2      yuri_2022   It's the land of the freebies for NYC's 'enti...   \n",
       "3  SharkolyPamuk   [VIDEO] Joe Biden Has Another Outburst and St...   \n",
       "4    ZoneZeus123         Liberals giving this man 180 sentence only   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0   migrants occupy 288 a night nyc hotel refuse ...   \n",
       "1   breaking nikki haley to run for president in ...   \n",
       "2   its the land of the freebies for nycs entitle...   \n",
       "3   video joe biden has another outburst and star...   \n",
       "4         liberals giving this man 180 sentence only   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [migrants, occupy, 288, a, night, nyc, hotel, ...   \n",
       "1  [breaking, nikki, haley, to, run, for, preside...   \n",
       "2  [its, the, land, of, the, freebies, for, nycs,...   \n",
       "3  [video, joe, biden, has, another, outburst, an...   \n",
       "4  [liberals, giving, this, man, 180, sentence, o...   \n",
       "\n",
       "                                            out_sent  \n",
       "0  [migrant, occupy, 288, night, nyc, hotel, refu...  \n",
       "1     [breaking, nikki, haley, run, president, 2024]  \n",
       "2           [land, freebie, nycs, entitled, migrant]  \n",
       "3  [video, joe, biden, another, outburst, start, ...  \n",
       "4              [liberal, giving, man, 180, sentence]  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "sents.loc[:, 'out_sent'] = sents['tokens'].apply(lemma_er)\n",
    "sents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "86bd0cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = sents[['author', 'out_sent']]\n",
    "\n",
    "sents.to_csv('./data/utf8-lemma/reps_sents_p23.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e334c546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['troubled', 'relation', 'defining', 'successor', 'ideology']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents['out_sent'].iloc[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999dcc4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
